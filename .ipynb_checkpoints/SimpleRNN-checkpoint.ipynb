{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import wavfile \n",
    "from librosa.feature import mfcc\n",
    "from librosa import load\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "INPUT_SIZE = 20\n",
    "BATCH_SIZE = 100\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 10\n",
    "CELL_SIZE = 50\n",
    "LR = 5e-4\n",
    "\n",
    "PATH = 'free-spoken-digit-dataset-master/recordings'\n",
    "DIGITS = '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_files(test_pct=0.1, test_speaker=None):\n",
    "    D_train, D_test = [], []\n",
    "    for d in DIGITS:\n",
    "        for filename in [x for x in os.listdir(PATH) if x.endswith('.wav') and x.startswith(d)]:\n",
    "            filepath = os.path.join(PATH, filename)\n",
    "            sig, rate = load(filepath)\n",
    "\n",
    "            # Extract MFCC features\n",
    "            mfcc_features = mfcc(sig, rate).T\n",
    "            dp = np.vstack(([int(d)]*INPUT_SIZE, mfcc_features))\n",
    "            if test_speaker:\n",
    "                if test_speaker in filename:\n",
    "                    D_test.append(dp)\n",
    "                else:\n",
    "                    D_train.append(dp)\n",
    "            else:\n",
    "                D_train.append(dp)\n",
    "    if test_speaker:\n",
    "        lt = len(D_train)\n",
    "    else:\n",
    "        lt = int(len(D_train)*(1-test_pct))\n",
    "    D_train.extend(D_test)\n",
    "    D = tf.keras.preprocessing.sequence.pad_sequences(D_train, padding=\"post\")\n",
    "    if test_speaker:\n",
    "        D_train = D[:lt]\n",
    "        D_test = D[lt:]\n",
    "        np.random.shuffle(D_train)\n",
    "        np.random.shuffle(D_test)\n",
    "        X_train = [dp[1:] for dp in D_train]\n",
    "        X_test = [dp[1:] for dp in D_test]\n",
    "        y_train = [dp[0][0] for dp in D_train]\n",
    "        y_test = [dp[0][0] for dp in D_test]\n",
    "        y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "        y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "        return (np.array(X_train), y_train), (np.array(X_test), y_test)\n",
    "    else:\n",
    "        np.random.shuffle(D)\n",
    "        X = [dp[1:] for dp in D]\n",
    "        y = [dp[0][0] for dp in D]\n",
    "        y = np_utils.to_categorical(y, num_classes=10)\n",
    "        return (np.array(X[:lt]), y[:lt]), (np.array(X[lt:]), y[lt:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traind, testd = load_wav_files()\n",
    "X_train, y_train = traind\n",
    "X_test, y_test = testd\n",
    "scl = np.max(np.abs(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/scl\n",
    "X_test = X_test/scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "model.add(SimpleRNN(\n",
    "    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE),\n",
    "    units=CELL_SIZE,\n",
    "    activation=\"elu\",\n",
    "    kernel_initializer=\"orthogonal\",\n",
    "    recurrent_regularizer=\"l2\"\n",
    "))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(OUTPUT_SIZE))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# optimizer\n",
    "adam = Adam(tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    LR,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.94,\n",
    "    staircase=True))\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  2.79999041557312 train accuracy:  0.09370370209217072\n",
      "test loss:  2.802091121673584 test accuracy:  0.09333333373069763\n",
      "train loss:  1.8447370529174805 train accuracy:  0.41740739345550537\n",
      "test loss:  1.8977195024490356 test accuracy:  0.3799999952316284\n",
      "train loss:  1.448486328125 train accuracy:  0.597777783870697\n",
      "test loss:  1.5100284814834595 test accuracy:  0.5600000023841858\n",
      "train loss:  1.1955831050872803 train accuracy:  0.7062963247299194\n",
      "test loss:  1.2538082599639893 test accuracy:  0.653333306312561\n",
      "train loss:  1.0415067672729492 train accuracy:  0.7651851773262024\n",
      "test loss:  1.0619148015975952 test accuracy:  0.7433333396911621\n",
      "train loss:  0.9965206980705261 train accuracy:  0.7781481742858887\n",
      "test loss:  1.0202271938323975 test accuracy:  0.7733333110809326\n",
      "train loss:  0.9517961740493774 train accuracy:  0.8018518686294556\n",
      "test loss:  1.0015106201171875 test accuracy:  0.7866666913032532\n",
      "train loss:  0.9474383592605591 train accuracy:  0.79666668176651\n",
      "test loss:  0.9918321967124939 test accuracy:  0.7866666913032532\n",
      "train loss:  0.9600698351860046 train accuracy:  0.7855555415153503\n",
      "test loss:  0.9984115362167358 test accuracy:  0.7799999713897705\n",
      "train loss:  0.8681568503379822 train accuracy:  0.8274074196815491\n",
      "test loss:  0.9393255710601807 test accuracy:  0.8066666722297668\n",
      "train loss:  0.8412655591964722 train accuracy:  0.8399999737739563\n",
      "test loss:  0.9075992703437805 test accuracy:  0.8233333230018616\n",
      "train loss:  0.8302993774414062 train accuracy:  0.8399999737739563\n",
      "test loss:  0.9089564085006714 test accuracy:  0.8333333134651184\n",
      "train loss:  0.82491534948349 train accuracy:  0.8396296501159668\n",
      "test loss:  0.8908748626708984 test accuracy:  0.8133333325386047\n",
      "train loss:  0.8062020540237427 train accuracy:  0.8481481671333313\n",
      "test loss:  0.8924956321716309 test accuracy:  0.8333333134651184\n",
      "train loss:  0.7920225858688354 train accuracy:  0.8544444441795349\n",
      "test loss:  0.896693229675293 test accuracy:  0.846666693687439\n",
      "train loss:  0.7847952842712402 train accuracy:  0.863703727722168\n",
      "test loss:  0.9077104926109314 test accuracy:  0.8399999737739563\n",
      "train loss:  0.7798453569412231 train accuracy:  0.8640740513801575\n",
      "test loss:  0.9217746257781982 test accuracy:  0.8399999737739563\n",
      "train loss:  0.7765994071960449 train accuracy:  0.8633333444595337\n",
      "test loss:  0.9316415190696716 test accuracy:  0.8399999737739563\n",
      "train loss:  0.7635059356689453 train accuracy:  0.8659259080886841\n",
      "test loss:  0.9272597432136536 test accuracy:  0.8433333039283752\n",
      "train loss:  0.7511898279190063 train accuracy:  0.8751851916313171\n",
      "test loss:  0.9267147779464722 test accuracy:  0.8333333134651184\n",
      "train loss:  0.7531607151031494 train accuracy:  0.8718518614768982\n",
      "test loss:  0.9426580667495728 test accuracy:  0.8299999833106995\n",
      "train loss:  0.7416038513183594 train accuracy:  0.8733333349227905\n",
      "test loss:  0.9202195405960083 test accuracy:  0.8299999833106995\n",
      "train loss:  0.732940137386322 train accuracy:  0.877407431602478\n",
      "test loss:  0.9146245121955872 test accuracy:  0.8299999833106995\n",
      "train loss:  0.7285885810852051 train accuracy:  0.8762962818145752\n",
      "test loss:  0.914600133895874 test accuracy:  0.8366666436195374\n",
      "train loss:  0.7243766784667969 train accuracy:  0.8785185217857361\n",
      "test loss:  0.91131991147995 test accuracy:  0.8366666436195374\n",
      "train loss:  0.7209621667861938 train accuracy:  0.8792592883110046\n",
      "test loss:  0.9089481830596924 test accuracy:  0.8366666436195374\n",
      "train loss:  0.7165588140487671 train accuracy:  0.881851851940155\n",
      "test loss:  0.9017993211746216 test accuracy:  0.8366666436195374\n",
      "train loss:  0.7133270502090454 train accuracy:  0.8833333253860474\n",
      "test loss:  0.8963600397109985 test accuracy:  0.8333333134651184\n",
      "train loss:  0.7109194993972778 train accuracy:  0.8837037086486816\n",
      "test loss:  0.8921204805374146 test accuracy:  0.8366666436195374\n",
      "train loss:  0.7089813947677612 train accuracy:  0.8844444155693054\n",
      "test loss:  0.8906899094581604 test accuracy:  0.8333333134651184\n",
      "train loss:  0.7075393199920654 train accuracy:  0.8844444155693054\n",
      "test loss:  0.8891214728355408 test accuracy:  0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for step in range(30001):\n",
    "    # data shape = (batch_num, steps, inputs/outputs)\n",
    "    X_batch = X_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :, :]\n",
    "    Y_batch = y_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :]\n",
    "    cost = model.train_on_batch(X_batch, Y_batch)\n",
    "    BATCH_INDEX += BATCH_SIZE\n",
    "    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        loss, accuracy = model.evaluate(X_train, y_train, batch_size=y_train.shape[0], verbose=False)\n",
    "        print('train loss: ', loss, 'train accuracy: ', accuracy)\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "        print('test loss: ', loss, 'test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=-1)\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  0,  2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0, 25,  0,  0,  3,  5,  0,  0,  0,  0],\n",
       "       [ 1,  0, 25,  1,  0,  0,  0,  0,  1,  0],\n",
       "       [ 4,  0,  1, 22,  0,  0,  4,  2,  0,  0],\n",
       "       [ 6,  1,  0,  0, 36,  0,  0,  0,  0,  0],\n",
       "       [ 0,  5,  0,  0,  0, 26,  0,  0,  0,  3],\n",
       "       [ 0,  0,  1,  0,  0,  0, 28,  0,  3,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0, 16,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  3,  0, 23,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0, 21]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
