{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import wavfile \n",
    "from hmmlearn import hmm\n",
    "from librosa.feature import mfcc\n",
    "from librosa import load\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_files(\n",
    "    path='free-spoken-digit-dataset-master/recordings', \n",
    "    digit='0',\n",
    "    test_pct=0.1,\n",
    "    test_speaker=None\n",
    "    ):\n",
    "    X_train, X_test = [], []\n",
    "    len_train, len_test = [], []\n",
    "    for filename in [x for x in os.listdir(path) if x.endswith('.wav') and x.startswith(digit)]:\n",
    "        # Read the input file\n",
    "        # print(filename)\n",
    "        filepath = os.path.join(path, filename)\n",
    "        sig, rate = load(filepath)\n",
    "\n",
    "        # Extract MFCC features\n",
    "        mfcc_features = mfcc(sig, rate).T\n",
    "        \n",
    "        if test_speaker:\n",
    "            if test_speaker in filename:\n",
    "                X_test.extend(mfcc_features)\n",
    "                len_test.append(mfcc_features.shape[0])\n",
    "            else:\n",
    "                X_train.extend(mfcc_features)\n",
    "                len_train.append(mfcc_features.shape[0])\n",
    "        else:\n",
    "            if np.random.uniform() < test_pct:\n",
    "                X_test.extend(mfcc_features)\n",
    "                len_test.append(mfcc_features.shape[0])\n",
    "            else:\n",
    "                X_train.extend(mfcc_features)\n",
    "                len_train.append(mfcc_features.shape[0])\n",
    "            \n",
    "    return (np.array(X_train), len_train), (np.array(X_test), len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = '0123456789'\n",
    "\n",
    "def train_models(test_speaker=None):\n",
    "    models = {}\n",
    "    testdata = {}\n",
    "    print('Training Models...')\n",
    "    for d in digits:\n",
    "        sys.stdout.write(d + ' ')\n",
    "        traind, testd = load_wav_files(digit=d, test_speaker=test_speaker)\n",
    "        xd, ld = traind\n",
    "        hmmd = hmm.GaussianHMM(n_components=5, n_iter=100)\n",
    "        hmmd.fit(xd, ld)\n",
    "        models[d] = hmmd\n",
    "        testdata[d] = testd\n",
    "    print()\n",
    "    return models, testdata\n",
    "        \n",
    "def evaluate_models(models, testdata):\n",
    "    print('Evaluating Performance...')\n",
    "    y_true, y_pred = [], []\n",
    "    for d in digits:\n",
    "        sys.stdout.write(d + ' ')\n",
    "        xd, ld = testdata[d]\n",
    "        xd = np.split(xd, np.cumsum(ld))[:-1]\n",
    "        for td in xd:\n",
    "            scores = [models[di].score(td) for di in digits]\n",
    "            y_true.append(d)\n",
    "            y_pred.append(str(scores.index(max(scores))))\n",
    "    print()\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: HMM With Random Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Evaluating Performance...\n",
      "0 1 2 3 4 5 6 7 8 9 \n"
     ]
    }
   ],
   "source": [
    "models, testdata = train_models()\n",
    "y_true, y_pred = evaluate_models(models, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  1,  0,  2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 21,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  1, 28,  4,  0,  0,  0,  0,  0,  0],\n",
       "       [ 6,  0,  2, 19,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 30,  0,  0,  0,  0,  0],\n",
       "       [ 0,  3,  0,  0,  0, 25,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  2,  0,  0, 25,  0,  3,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0, 29,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  2,  0,  0, 23,  0],\n",
       "       [ 0,  4,  0,  1,  0,  2,  0,  0,  0, 27]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: HMM Testing on New Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = ['george', 'jackson', 'lucas', 'nicolas', 'theo', 'yweweler']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Speaker `george`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Evaluating Performance...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Results:\n",
      "[[ 0  1  7 42  0  0  0  0  0  0]\n",
      " [ 0 41  0  9  0  0  0  0  0  0]\n",
      " [ 0  5 11 34  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 0  4  0 46  0  0  0  0  0  0]\n",
      " [ 0 12  0 38  0  0  0  0  0  0]\n",
      " [ 0  0  3 47  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 0  0  5 45  0  0  0  0  0  0]\n",
      " [ 0  2  0 46  0  0  0  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "models, testdata = train_models(test_speaker='george')\n",
    "y_true, y_pred = evaluate_models(models, testdata)\n",
    "print('Results:')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Speaker `jackson`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Evaluating Performance...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Results:\n",
      "[[50  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 48  0  0  2  0  0  0  0  0]\n",
      " [ 1  0 48  1  0  0  0  0  0  0]\n",
      " [13  0  2 30  0  0  2  0  0  3]\n",
      " [ 0  0  0  0 50  0  0  0  0  0]\n",
      " [ 0 17  0  0  0 22  0  5  0  6]\n",
      " [ 0  2  0  0  1  0  2 37  2  6]\n",
      " [ 0  0  0  0  0  0  0 50  0  0]\n",
      " [ 0  0  0  6  0  0 16  0 28  0]\n",
      " [ 2 13  0  0  0  0  0  4  0 31]]\n"
     ]
    }
   ],
   "source": [
    "models, testdata = train_models(test_speaker='jackson')\n",
    "y_true, y_pred = evaluate_models(models, testdata)\n",
    "print('Results:')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Speaker `lucas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Evaluating Performance...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Results:\n",
      "[[16  0  0 31  3  0  0  0  0  0]\n",
      " [ 0 37  0 12  0  0  0  0  0  1]\n",
      " [ 0  0  1 49  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 4  6  0  7 33  0  0  0  0  0]\n",
      " [ 0  0  0  5  0 45  0  0  0  0]\n",
      " [ 0  0  0 19  0 30  0  1  0  0]\n",
      " [ 0  0  0 30  0  1  0 19  0  0]\n",
      " [ 0  0  0 43  0  0  0  0  7  0]\n",
      " [ 0  4  0  3  0  0  0  0  0 43]]\n"
     ]
    }
   ],
   "source": [
    "models, testdata = train_models(test_speaker='lucas')\n",
    "y_true, y_pred = evaluate_models(models, testdata)\n",
    "print('Results:')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Speaker `nicolas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Evaluating Performance...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Results:\n",
      "[[43  0  5  0  0  0  2  0  0  0]\n",
      " [ 5  3 35  0  0  0  1  2  0  4]\n",
      " [37  0  9  0  0  0  4  0  0  0]\n",
      " [19  0  1  0  0  0 30  0  0  0]\n",
      " [ 2 12 17  0 17  0  0  2  0  0]\n",
      " [ 0 12 24  0  0  7  2  0  0  5]\n",
      " [ 5  0  2  0  0  0 39  0  4  0]\n",
      " [ 7  0  0  0  0  0 39  4  0  0]\n",
      " [ 1  0 11  2  0  0 33  0  3  0]\n",
      " [28  0  2  1  0  2  0  8  0  9]]\n"
     ]
    }
   ],
   "source": [
    "models, testdata = train_models(test_speaker='nicolas')\n",
    "y_true, y_pred = evaluate_models(models, testdata)\n",
    "print('Results:')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Speaker `theo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Evaluating Performance...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Results:\n",
      "[[ 5  0 12  0  0  4 13 10  1  5]\n",
      " [ 0 45  0  0  0  1  0  0  0  4]\n",
      " [ 1  0 37  0  0  0 12  0  0  0]\n",
      " [ 0  0 17  8  0  0 22  0  3  0]\n",
      " [ 7 27  0  0 13  1  0  2  0  0]\n",
      " [ 0  0  0  0  0 21  0  0  0 29]\n",
      " [ 0  0 23  0  0  0  5 19  3  0]\n",
      " [ 0  0  0  0  0 20  1 28  0  1]\n",
      " [ 0  0  3  0  0  0  2  0 45  0]\n",
      " [ 0  4  0  0  0  6  0  2  0 38]]\n"
     ]
    }
   ],
   "source": [
    "models, testdata = train_models(test_speaker='theo')\n",
    "y_true, y_pred = evaluate_models(models, testdata)\n",
    "print('Results:')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Speaker `yweweler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Evaluating Performance...\n",
      "0 1 2 3 4 5 6 7 8 9 \n",
      "Results:\n",
      "[[44  2  0  4  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  0  0]\n",
      " [14  1 34  0  0  0  0  1  0  0]\n",
      " [ 2  0  7 33  0  0  1  0  7  0]\n",
      " [ 0 12  0  0 38  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 18  1  0  0 31]\n",
      " [ 4  0 19  1  0  0  2  0 23  1]\n",
      " [ 0  0  0  0  0  0  0 22  0 28]\n",
      " [ 0  0  5  0  0  0  1  0 44  0]\n",
      " [ 0  9  0  0  0  0  0  0  0 41]]\n"
     ]
    }
   ],
   "source": [
    "models, testdata = train_models(test_speaker='yweweler')\n",
    "y_true, y_pred = evaluate_models(models, testdata)\n",
    "print('Results:')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
